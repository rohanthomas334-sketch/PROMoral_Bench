# ğŸš€ ProMoral-Bench GitHub Setup Instructions

## âœ… What You Have

You have a complete `promoral-bench` directory with:
- âœ“ All documentation files (README, CONTRIBUTING, etc.)
- âœ“ All configuration files (requirements.txt, setup.py, etc.)
- âœ“ All your experimental results in the `results/` folder
- âœ“ Empty directories for data, prompts, and source code

## ğŸ“‹ Quick Steps (5 Simple Commands)

### Step 1: Download the Repository Folder

Download the entire `promoral-bench` directory to your computer.

### Step 2: Create GitHub Repository

Go to https://github.com/new and create a new repository:
- Repository name: `promoral-bench`
- Description: "Benchmark for evaluating prompting strategies in moral reasoning and safety"
- âœ“ Private (keep it private for now)
- â˜ Do NOT add README, .gitignore, or license (you already have these)

### Step 3: Open Terminal and Navigate to Directory

```bash
cd /path/to/promoral-bench
```

### Step 4: Initialize Git and Push to GitHub

```bash
# Initialize git repository
git init

# Add all files
git add .

# Commit
git commit -m "Initial commit: ProMoral-Bench v1.0"

# Add your GitHub repository as remote (replace YOUR-USERNAME)
git remote add origin https://github.com/YOUR-USERNAME/promoral-bench.git

# Push to GitHub
git branch -M main
git push -u origin main
```

### Step 5: Verify on GitHub

Go to your repository on GitHub and verify all files are there!

---

## ğŸ“ Current Repository Structure

```
promoral-bench/
â”œâ”€â”€ README.md                   âœ“ Complete with all costs and runtimes
â”œâ”€â”€ CONTRIBUTING.md             âœ“ Contribution guidelines
â”œâ”€â”€ LICENSE                     âœ“ MIT License
â”œâ”€â”€ REPRODUCTION_GUIDE.md       âœ“ Step-by-step reproduction
â”œâ”€â”€ DATA_PREPARATION.md         âœ“ Dataset formatting guide
â”œâ”€â”€ RESULTS_FORMAT.md           âœ“ CSV format specifications
â”œâ”€â”€ REPOSITORY_CHECKLIST.md     âœ“ Completion checklist
â”œâ”€â”€ SUMMARY.md                  âœ“ Overview document
â”œâ”€â”€ requirements.txt            âœ“ Python dependencies
â”œâ”€â”€ setup.py                    âœ“ Package installation
â”œâ”€â”€ .env.example                âœ“ API key template
â”œâ”€â”€ .gitignore                  âœ“ Git ignore rules
â”œâ”€â”€ results/                    âœ“ ALL YOUR EXPERIMENTAL DATA
â”‚   â”œâ”€â”€ ETHICS/                 (Raw results by model/strategy)
â”‚   â”œâ”€â”€ SCRUPLES/               (Raw results by model/strategy)
â”‚   â”œâ”€â”€ ETHICS CONTRAST/        (Raw results by model/strategy)
â”‚   â””â”€â”€ WildJailbreak/          (Raw results by model/strategy)
â”œâ”€â”€ data/                       â³ Empty (add datasets later)
â”œâ”€â”€ prompts/                    â³ Empty (add prompt templates later)
â”‚   â”œâ”€â”€ templates/
â”‚   â””â”€â”€ demonstrations/
â””â”€â”€ scripts/                    â³ Empty (add scripts later)
```

---

## ğŸ”§ Optional: Organize Results by Model (Later)

Your results are currently in raw format organized by folders. If you want to create the clean CSV files mentioned in the paper (one per model per dataset), you can do this later:

1. Extract code from your Jupyter notebook
2. Create a script to parse the results directories
3. Generate clean CSVs like `gpt-4.1_ethics_results.csv`

**But this is NOT required to publish your repository!** The raw data is completely acceptable and reviewers can verify everything.

---

## ğŸ“ What Reviewers Need

For AAAI 2026 AIR-FM Workshop submission, reviewers need:

### âœ… You Already Have:
- [x] Complete README with compute costs and runtimes
- [x] All experimental results (in `results/` folder)
- [x] Reproduction guide
- [x] Dataset format specifications
- [x] Contribution guidelines
- [x] MIT License

### â³ Optional (Can Add Later):
- [ ] Cleaned/organized result CSVs (nice to have, not required)
- [ ] Source code from Jupyter notebook (required eventually)
- [ ] Prompt template files (can be in paper appendix for now)
- [ ] Dataset files (can reference originals for now)

---

## ğŸ¯ Immediate Next Steps

1. **NOW**: Push to GitHub using commands above
2. **TODAY**: Update paper with GitHub link
3. **THIS WEEK**: Extract and add source code from notebook
4. **BEFORE SUBMISSION**: Test that someone can clone and understand repo

---

## ğŸ’¡ Pro Tips

### Making Repository Public

Keep private until paper is accepted, then:
```bash
# Go to repository settings on GitHub
# Scroll to "Danger Zone"
# Click "Change repository visibility"
# Select "Public"
```

### Adding Collaborators

```
# Go to repository settings â†’ Collaborators
# Add co-authors' GitHub usernames
```

### Creating Releases

After paper acceptance:
```bash
git tag -a v1.0.0 -m "ProMoral-Bench v1.0 - AAAI 2026"
git push origin v1.0.0
```

Then create a release on GitHub with DOI from Zenodo.

---

## â“ Common Questions

**Q: Do I need to clean up the results folders?**
A: No! The raw data is fine. Reviewers can verify everything from it.

**Q: What about the source code?**
A: Extract it from your Jupyter notebook and add it later. Not urgent.

**Q: Should I add the datasets?**
A: You can reference the original datasets for now (ETHICS, Scruples, WildJailbreak) and just include your ETHICS-Contrast pairs.

**Q: Can I change things after pushing?**
A: Yes! Git allows you to add, modify, and push updates anytime.

**Q: What if I mess up?**
A: You can always delete the GitHub repository and start over. No harm done!

---

## ğŸ†˜ Getting Help

If you get stuck:

### Git Issues
- **"Permission denied"**: Set up SSH keys or use HTTPS with personal access token
- **"Already exists"**: Use `git remote remove origin` then add again
- **"Diverged branches"**: Use `git pull origin main --rebase`

### GitHub Issues
- Check GitHub's documentation: https://docs.github.com/
- Or use GitHub Desktop app (easier visual interface)

### Repository Issues
- Everything is documented in the .md files
- Check REPOSITORY_CHECKLIST.md for deployment steps
- See SUMMARY.md for overview

---

## âœ¨ You're Almost Done!

**All documentation is complete.**
**All experimental data is organized.**
**All you need to do is push 5 commands to GitHub!**

ğŸ‰ Good luck with your AAAI submission!

---

**Last Updated**: November 6, 2025
**Status**: Ready to push to GitHub
**Time to complete**: 5 minutes
